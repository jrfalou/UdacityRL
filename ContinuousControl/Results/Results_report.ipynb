{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Models tested\n",
    "\n",
    "We tried and trained a DDPG algo with different sets of parameters:\n",
    "- learning batch sizes for values [50, 100, 150, 200, 250]\n",
    "- number of steps between learning steps for values [1, 4, 8, 12, 16, 20]\n",
    "- Ornstein-Uhlenbeck process (theta, sigma) for values [(0.15, 0.2), (0, 0)]\n",
    "- Actor & Critic learning rates for values [(1e-4, 1e-3), (1e-3, 1e-3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation\n",
    "\n",
    "A DDPG model will be identified by the following string: \n",
    "\"[batch_size]_[nb_learning_steps]_[actor_lr]_[critic_lr]_[noise_theta]_[noise_sigma]_[actor_hidden_layers]_[critic_hidden_layer]\"\n",
    "\n",
    "For instance \"150_8_0.001_0.001_0.15_0.1_(128, 128)_(128, 128)\" designates a DDPG algo trained with:\n",
    "- an actor neural network composed of 2 hidden layers fully connected of 128 nodes each\n",
    "- a critic neural network composed of 2 hidden layers fully connected of 128 nodes each\n",
    "- using a learning batch size of 150 steps at a time\n",
    "- every 8 steps\n",
    "- with an actor learning rate of 1e-3\n",
    "- and a critic learning rate of 1e-3\n",
    "- with noise parameters of (theta = 0.15, sigma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import results_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training results\n",
    "\n",
    "Below we gather the results of all the training runs tried with different sets of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results from all training runs contained in the Results directory\n",
    "df_results_step, df_results, df_details = results_analysis.get_training_results()\n",
    "\n",
    "# Get best training runs\n",
    "# best_results_step finds the highest step-values among all training runs\n",
    "# best_results finds the highest end-of-episode values among all training runs\n",
    "best_results_step, best_results = results_analysis.get_best_runs(df_results_step, df_results, nb_runs=5)\n",
    "\n",
    "display(best_results_step.iloc[:5])\n",
    "display(best_results.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parameter analysis\n",
    "\n",
    "In order to find the best model, I used the first training runs I had done and tried to keep the variation of each parameter that got the \"best\" results over all the runs (looking at max and mean values)\n",
    "\n",
    "After running some more training passes with the most promising combinations of parameter values, I got the below summary table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_summary contains some statistics for each parameter values tried\n",
    "parameters_summary = results_analysis.get_stats_per_parameter(df_details)\n",
    "display(parameters_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Best model\n",
    "\n",
    "I selected as \"best model\" the one that reached an average score of 30 the fastest; in 782 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = best_results.index[0][1]\n",
    "\n",
    "display(df_results[df_results['model_tag']==selected_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Training plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot 100-steps average scores\n",
    "training_run, selected_model = best_results.index[0]\n",
    "results_analysis.plot_model(df_results_step, df_results, training_run, selected_model, by_step=False, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all steps\n",
    "results_analysis.plot_model(df_results_step, df_results, training_run, selected_model, by_step=True, kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### 4.2 Test\n",
    "\n",
    "Below a test run using the selected \"best model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\J\\Programming\\Visual Studio Code\\UdacityRL\\ContinuousControl\n",
      "selected_model 150_8_0.001_0.001_0.15_0.1_(128, 128)_(128, 128)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import results_analysis\n",
    "\n",
    "#You need to be at the root directory of the navigation directory to run the model in the next cell\n",
    "os.chdir('..')\n",
    "print(os.getcwd())\n",
    "\n",
    "try:\n",
    "    selected_model = best_results.index[0][1]\n",
    "except:\n",
    "    selected_model = '150_8_0.001_0.001_0.15_0.1_(128, 128)_(128, 128)'\n",
    "\n",
    "print('selected_model', selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model weights ./ModelWeights/150_8_0.001_0.001_0.15_0.1_(128, 128)_(128, 128).pth\n",
      "Score: 38.27"
     ]
    }
   ],
   "source": [
    "#If you get the \"handle is closed\" error, you need to restart your kernel and execute from the Conclusion first cell; \n",
    "#I don't know how to fix that\n",
    "%run -i continuous_control.py test --test_params=best_params.json --test_model=\"auto\" --test_results_path=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
